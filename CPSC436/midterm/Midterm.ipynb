{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Project: Regularized Logistic Regression with Real Dataset\n",
    "\n",
    "An extension of Logistic Regression with a real dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "    1. Upload and transform real valued dataset\n",
    "    2. Scale the dataset using z-score normalization\n",
    "    3. Implement regularization (extending compute_cose and compute_gradient functions)\n",
    "    4. Plot the learning curve (cost vs iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "First, we must import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset\n",
    "This dataset is a dataset of diagnostic breast cancer data which includes 30 real values input features. These features encompass many medical attributes about each patient's tumor. Specifically, the 30 real valued features are computed from 10 attributes about each cell in the tumor. For each of the 10 attributes, the mean, standard error, and mean of the three largest values are recorded, resulting in 30 input features for our regression model. In addition to these features, each data point has an id number and a result, whether the tumor was malignant or benign.\n",
    "\n",
    "Here we load this dataset:\n",
    "  - `X_train` contains the 30 real valued input features\n",
    "  - `y_train` is the diagnostic decision\n",
    "      - `y_train = 1` if the patient's tumor was malignant \n",
    "      - `y_train = 0` if the patient's tumor was benign\n",
    "  - Both `X_train` and `y_train` are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, dtype=str, delimiter=',')\n",
    "\n",
    "    X = data[:,2:].astype(np.float)\n",
    "    y = [1 if item == 'M' else 0 for item in data[:,1]]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "X_train, y_train = load_data(\"./data/wdbc.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation\n",
    "Here is a summary of some of the notation you will encounter, updated for multiple features.  \n",
    "\n",
    "|General <img width=70/> <br />  Notation  <img width=70/> | Description<img width=350/>| Python (if applicable) |\n",
    "|: ------------|: ------------------------------------------------------------||\n",
    "| $a$ | scalar, non bold                                                      ||\n",
    "| $\\mathbf{a}$ | vector, bold                                                 ||\n",
    "| $\\mathbf{A}$ | matrix, bold capital                                         ||\n",
    "| **Regression** |         |    |     |\n",
    "|  $\\mathbf{X}$ | training example maxtrix                  | `X_train` |   \n",
    "|  $\\mathbf{y}$  | training example  targets                | `y_train` \n",
    "|  $\\mathbf{x}^{(i)}$, $y^{(i)}$ | $i_{th}$Training Example | `X[i]`, `y[i]`|\n",
    "| m | number of training examples | `m`|\n",
    "| n | number of features in each example | `n`|\n",
    "|  $\\mathbf{w}$  |  parameter: weight,                       | `w`    |\n",
    "|  $b$           |  parameter: bias                                           | `b`    |     \n",
    "| $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ | The result of the model evaluation at $\\mathbf{x^{(i)}}$ parameterized by $\\mathbf{w},b$: $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+b$  | `f_wb` | \n",
    "\n",
    "\n",
    "### Normalization\n",
    "Here we will use the z score normalization technique to normalize the dataset.\n",
    "\n",
    "After z-score normalization, all features will have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "To implement z-score normalization, adjust your input values as shown in this formula:\n",
    "$$x^{(i)}_j = \\dfrac{x^{(i)}_j - \\mu_j}{\\sigma_j} \\tag{4}$$ \n",
    "where $j$ selects a feature or a column in the $\\mathbf{X}$ matrix. $Âµ_j$ is the mean of all the values for feature (j) and $\\sigma_j$ is the standard deviation of feature (j).\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} x^{(i)}_j \\tag{5}\\\\\n",
    "\\sigma^2_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} (x^{(i)}_j - \\mu_j)^2  \\tag{6}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalize_features(X):\n",
    "    \"\"\"\n",
    "    computes  X, zcore normalized by column\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))     : input data, m examples, n features\n",
    "      \n",
    "    Returns:\n",
    "      X_norm (ndarray (m,n)): input normalized by column\n",
    "      mu (ndarray (n,))     : mean of each feature\n",
    "      sigma (ndarray (n,))  : standard deviation of each feature\n",
    "    \"\"\"\n",
    "    # find the mean of each column/feature\n",
    "    mu     = np.mean(X, axis=0)                 # mu will have shape (n,)\n",
    "    # find the standard deviation of each column/feature\n",
    "    sigma  = np.std(X, axis=0)                  # sigma will have shape (n,)\n",
    "    # element-wise, subtract mu for that column from each example, divide by std for that column\n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return X_norm\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the original features\n",
    "X_norm = zscore_normalize_features(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "Here we will extend the compute cost and compute gradient functions to utilize regularization techniques to avoid overfitting.\n",
    "\n",
    "Cost function and regression function for Regularized Logistic Regression:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&J(\\vec{w}, b)=-\\frac{1}{m} \\sum_{i=1}^m\\left[y^{(i)} \\log \\left(f_{\\vec{w}, b}\\left(\\vec{x}^{(i)}\\right)\\right)+\\left(1-y^{(i)}\\right) \\log \\left(1-f_{\\vec{w}, b}\\left(\\vec{x}^{(i)}\\right)\\right)\\right]+\\frac{\\lambda}{2 m} \\sum_{j=1}^n w_j^2\\\\\n",
    "&\\text { repeat }\\{\\\\\n",
    "&w_j=w_j-\\alpha\\left[\\frac{1}{m} \\sum_{i=1}^m\\left[\\left(f_{\\vec{w}, b}\\left(\\vec{x}^{(i)}\\right)-y^{(i)}\\right) x_j^i\\right]+\\frac{\\lambda}{m} w_j\\right]\\\\\n",
    "&b=b-\\alpha\\left[\\frac{1}{m} \\sum_{i=1}^m\\left(f_{\\vec{w}, b}\\left(\\vec{x}^{(i)}\\right)-y^{(i)}\\right)\\right]\\\\\n",
    "&\\}\\\\\n",
    "&\\text { Where } f_{\\vec{w}, b}(\\vec{x})=\\frac{1}{1+e^{-(\\vec{w} \\cdot \\vec{x}+b)}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Args:\n",
    "        z (ndarray): A scalar, numpy array of any size.\n",
    "\n",
    "    Returns:\n",
    "        g (ndarray): sigmoid(z), with the same shape as z\n",
    "         \n",
    "    \"\"\"\n",
    "    g = (1/(1+np.exp(-z)))\n",
    "    return g\n",
    "\n",
    "def compute_cost(X, y, w, b, lambda_= 1):\n",
    "    \"\"\"\n",
    "    Computes the cost over all examples\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      y : (array_like Shape (m,)) target value \n",
    "      w : (array_like Shape (n,)) Values of parameters of the model      \n",
    "      b : scalar Values of bias parameter of the model\n",
    "      lambda_: scalar value for regularization\n",
    "    Returns:\n",
    "      total_cost: (scalar)         cost \n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "\n",
    "    total_cost = ((-1/m)*sum_losses(X, y, w, b, m))+((lambda_/(2*m))*sum_of_squared_features(w, n))\n",
    "    \n",
    "    \n",
    "    return total_cost\n",
    "\n",
    "def sum_of_squared_features(w, n):\n",
    "    return sum([w[j]**2 for j in range(n)])\n",
    "\n",
    "\n",
    "def sum_losses(X, y, w, b, m):\n",
    "    return sum([loss(sigmoid(np.dot(w, X[i])+b), y[i]) for i in range(m)])\n",
    "\n",
    "\n",
    "def loss(fwbx, y):\n",
    "    return (y*np.log(fwbx)) + (1-y)*np.log(1-fwbx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "Here we calculate the gradient for logistic regression with regularization and use it to calculate the gradient descent to learn theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b, lambda_=None): \n",
    "    \"\"\"\n",
    "    Computes the gradient for logistic regression \n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) variable such as house size \n",
    "      y : (array_like Shape (m,1)) actual value \n",
    "      w : (array_like Shape (n,1)) values of parameters of the model      \n",
    "      b : (scalar)                 value of parameter of the model \n",
    "      lambda_: scalar value for regularization\n",
    "    Returns\n",
    "      dj_dw: (array_like Shape (n,1)) The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db: (scalar)                The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros(w.shape)\n",
    "    dj_db = 0.\n",
    "\n",
    "    dj_db = (1/m)*sum([sigmoid(np.dot(X[i], w)+b)-y[i] for i in range(m)])\n",
    "    \n",
    "    dj_dw = (1/m)*sum([(sigmoid(np.dot(X[i], w)+b)-y[i])*X[i] for i in range(m)])+ ((lambda_/m)*w)\n",
    "\n",
    "    \n",
    "    return dj_db, dj_dw\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X :    (array_like Shape (m, n)\n",
    "      y :    (array_like Shape (m,))\n",
    "      w_in : (array_like Shape (n,))  Initial values of parameters of the model\n",
    "      b_in : (scalar)                 Initial value of parameter of the model\n",
    "      cost_function:                  function to compute cost\n",
    "      alpha : (float)                 Learning rate\n",
    "      num_iters : (int)               number of iterations to run gradient descent\n",
    "      lambda_ (scalar, float)         regularization constant\n",
    "      \n",
    "    Returns:\n",
    "      w : (array_like Shape (n,)) Updated values of parameters of the model after\n",
    "          running gradient descent\n",
    "      b : (scalar)                Updated value of parameter of the model after\n",
    "          running gradient descent\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of training examples\n",
    "    m = len(X)\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db, dj_dw = gradient_function(X, y, w_in, b_in, lambda_)   \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w_in = w_in - alpha*dj_dw               \n",
    "        b_in = b_in - alpha*dj_db              \n",
    "       \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            cost =  cost_function(X, y, w_in, b_in, lambda_)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1):\n",
    "            w_history.append(w_in)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w_in, b_in, J_history, w_history #return w and J,w history for graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Here we run gradient descent for our model with some parameters we can experiment with to get the best results. A larger alpha means that the weights and biases are modified more at every step. A larger lambda means more regulization is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     0.69   \n",
      "Iteration 1000: Cost     0.25   \n",
      "Iteration 2000: Cost     0.19   \n",
      "Iteration 3000: Cost     0.16   \n",
      "Iteration 4000: Cost     0.15   \n",
      "Iteration 5000: Cost     0.14   \n",
      "Iteration 6000: Cost     0.13   \n",
      "Iteration 7000: Cost     0.13   \n",
      "Iteration 8000: Cost     0.12   \n",
      "Iteration 9000: Cost     0.12   \n",
      "Iteration 9999: Cost     0.12   \n",
      "b,w found by gradient descent: -0.33,[ 0.36871781  0.32313821  0.36511082  0.36364845  0.13722045  0.13426724\n",
      "  0.28130855  0.37135542  0.10100307 -0.1566099   0.32108198  0.00231499\n",
      "  0.27656912  0.29478144 -0.00445448 -0.08629911 -0.07214296  0.06094345\n",
      " -0.06199763 -0.16763157  0.43350334  0.39224404  0.41734921  0.40814405\n",
      "  0.29043102  0.2011423   0.27759468  0.3924805   0.26841951  0.0987233 ] \n",
      "prediction: 9.79, target value: 1\n",
      "prediction: 4.52, target value: 1\n",
      "prediction: 7.53, target value: 1\n",
      "prediction: 4.59, target value: 1\n",
      "prediction: 4.65, target value: 1\n",
      "prediction: 1.32, target value: 1\n",
      "prediction: 4.44, target value: 1\n",
      "prediction: 1.76, target value: 1\n",
      "prediction: 3.11, target value: 1\n",
      "prediction: 4.93, target value: 1\n",
      "prediction: 0.66, target value: 1\n",
      "prediction: 3.28, target value: 1\n",
      "prediction: 6.45, target value: 1\n",
      "prediction: 0.33, target value: 1\n",
      "prediction: 3.00, target value: 1\n",
      "prediction: 4.73, target value: 1\n",
      "prediction: 1.59, target value: 1\n",
      "prediction: 5.58, target value: 1\n",
      "prediction: 8.68, target value: 1\n",
      "prediction: -1.78, target value: 0\n",
      "prediction: -2.70, target value: 0\n",
      "prediction: -6.22, target value: 0\n",
      "prediction: 3.49, target value: 1\n",
      "prediction: 8.54, target value: 1\n",
      "prediction: 8.00, target value: 1\n",
      "prediction: 7.39, target value: 1\n",
      "prediction: 4.21, target value: 1\n",
      "prediction: 4.19, target value: 1\n",
      "prediction: 5.87, target value: 1\n",
      "prediction: 1.90, target value: 1\n",
      "prediction: 8.36, target value: 1\n",
      "prediction: 2.26, target value: 1\n",
      "prediction: 6.19, target value: 1\n",
      "prediction: 7.38, target value: 1\n",
      "prediction: 3.80, target value: 1\n",
      "prediction: 4.46, target value: 1\n",
      "prediction: 1.43, target value: 1\n",
      "prediction: -4.79, target value: 0\n",
      "prediction: -0.47, target value: 1\n",
      "prediction: 0.78, target value: 1\n",
      "prediction: -1.58, target value: 1\n",
      "prediction: -0.13, target value: 1\n",
      "prediction: 9.39, target value: 1\n",
      "prediction: 1.22, target value: 1\n",
      "prediction: 0.55, target value: 1\n",
      "prediction: 6.66, target value: 1\n",
      "prediction: -6.77, target value: 0\n",
      "prediction: 1.81, target value: 1\n",
      "prediction: -2.99, target value: 0\n",
      "prediction: -1.24, target value: 0\n",
      "prediction: -4.14, target value: 0\n",
      "prediction: -3.79, target value: 0\n",
      "prediction: -4.49, target value: 0\n",
      "prediction: 4.09, target value: 1\n",
      "prediction: 0.68, target value: 1\n",
      "prediction: -3.71, target value: 0\n",
      "prediction: 7.38, target value: 1\n",
      "prediction: 2.58, target value: 1\n",
      "prediction: -4.29, target value: 0\n",
      "prediction: -6.53, target value: 0\n",
      "prediction: -4.91, target value: 0\n",
      "prediction: -4.59, target value: 0\n",
      "prediction: 3.89, target value: 1\n",
      "prediction: -6.02, target value: 0\n",
      "prediction: 2.39, target value: 1\n",
      "prediction: 2.69, target value: 1\n",
      "prediction: -4.19, target value: 0\n",
      "prediction: -4.33, target value: 0\n",
      "prediction: -1.70, target value: 0\n",
      "prediction: -4.05, target value: 0\n",
      "prediction: 5.32, target value: 1\n",
      "prediction: -7.32, target value: 0\n",
      "prediction: 6.75, target value: 1\n",
      "prediction: -0.94, target value: 1\n",
      "prediction: -3.45, target value: 0\n",
      "prediction: 2.64, target value: 1\n",
      "prediction: -2.97, target value: 0\n",
      "prediction: 6.28, target value: 1\n",
      "prediction: 11.97, target value: 1\n",
      "prediction: -2.69, target value: 0\n",
      "prediction: -2.46, target value: 0\n",
      "prediction: -0.05, target value: 0\n",
      "prediction: 14.22, target value: 1\n",
      "prediction: 5.20, target value: 1\n",
      "prediction: -2.96, target value: 0\n",
      "prediction: 5.14, target value: 1\n",
      "prediction: 0.47, target value: 1\n",
      "prediction: 6.07, target value: 1\n",
      "prediction: -1.65, target value: 0\n",
      "prediction: -0.09, target value: 0\n",
      "prediction: -1.39, target value: 0\n",
      "prediction: 0.18, target value: 1\n",
      "prediction: -3.02, target value: 0\n",
      "prediction: -2.11, target value: 0\n",
      "prediction: 2.89, target value: 1\n",
      "prediction: 6.52, target value: 1\n",
      "prediction: -4.20, target value: 0\n",
      "prediction: -5.75, target value: 0\n",
      "prediction: -4.26, target value: 0\n",
      "prediction: 0.43, target value: 1\n",
      "prediction: 0.55, target value: 1\n",
      "prediction: -7.52, target value: 0\n",
      "prediction: -3.38, target value: 0\n",
      "prediction: -3.53, target value: 0\n",
      "prediction: -4.59, target value: 0\n",
      "prediction: 1.98, target value: 1\n",
      "prediction: -1.57, target value: 0\n",
      "prediction: -3.47, target value: 0\n",
      "prediction: 15.12, target value: 1\n",
      "prediction: -2.54, target value: 0\n",
      "prediction: -4.97, target value: 0\n",
      "prediction: -2.27, target value: 0\n",
      "prediction: -0.51, target value: 0\n",
      "prediction: -4.49, target value: 0\n",
      "prediction: -4.93, target value: 0\n",
      "prediction: -2.75, target value: 0\n",
      "prediction: -6.85, target value: 0\n",
      "prediction: 3.70, target value: 1\n",
      "prediction: 5.49, target value: 1\n",
      "prediction: 2.57, target value: 1\n",
      "prediction: -4.29, target value: 0\n",
      "prediction: 4.59, target value: 1\n",
      "prediction: 13.61, target value: 1\n",
      "prediction: -1.84, target value: 0\n",
      "prediction: -3.73, target value: 0\n",
      "prediction: -3.43, target value: 0\n",
      "prediction: 0.70, target value: 1\n",
      "prediction: 3.40, target value: 1\n",
      "prediction: -0.10, target value: 0\n",
      "prediction: 6.78, target value: 1\n",
      "prediction: -3.50, target value: 0\n",
      "prediction: 2.53, target value: 1\n",
      "prediction: 2.74, target value: 1\n",
      "prediction: -0.82, target value: 0\n",
      "prediction: 4.61, target value: 1\n",
      "prediction: -1.75, target value: 1\n",
      "prediction: -3.71, target value: 0\n",
      "prediction: -4.36, target value: 0\n",
      "prediction: 3.48, target value: 1\n",
      "prediction: -4.36, target value: 0\n",
      "prediction: -7.20, target value: 0\n",
      "prediction: 1.95, target value: 1\n",
      "prediction: -3.70, target value: 0\n",
      "prediction: -2.41, target value: 0\n",
      "prediction: -5.92, target value: 0\n",
      "prediction: -4.18, target value: 0\n",
      "prediction: 0.77, target value: 1\n",
      "prediction: -1.65, target value: 0\n",
      "prediction: -1.02, target value: 0\n",
      "prediction: -3.54, target value: 0\n",
      "prediction: -1.91, target value: 0\n",
      "prediction: -3.86, target value: 0\n",
      "prediction: -2.85, target value: 0\n",
      "prediction: -5.30, target value: 0\n",
      "prediction: -1.78, target value: 0\n",
      "prediction: -3.21, target value: 0\n",
      "prediction: 4.46, target value: 1\n",
      "prediction: -0.22, target value: 0\n",
      "prediction: -4.85, target value: 0\n",
      "prediction: -5.94, target value: 0\n",
      "prediction: -1.92, target value: 0\n",
      "prediction: 4.14, target value: 1\n",
      "prediction: 8.84, target value: 1\n",
      "prediction: -2.63, target value: 0\n",
      "prediction: 8.96, target value: 1\n",
      "prediction: -2.70, target value: 0\n",
      "prediction: -6.46, target value: 0\n",
      "prediction: 2.02, target value: 1\n",
      "prediction: 6.87, target value: 1\n",
      "prediction: -1.99, target value: 0\n",
      "prediction: -3.82, target value: 0\n",
      "prediction: -0.02, target value: 1\n",
      "prediction: 2.31, target value: 1\n",
      "prediction: -6.32, target value: 0\n",
      "prediction: -6.19, target value: 0\n",
      "prediction: -7.86, target value: 0\n",
      "prediction: -4.66, target value: 0\n",
      "prediction: 2.99, target value: 1\n",
      "prediction: -4.85, target value: 0\n",
      "prediction: -5.52, target value: 0\n",
      "prediction: 14.99, target value: 1\n",
      "prediction: 11.46, target value: 1\n",
      "prediction: 2.31, target value: 1\n",
      "prediction: -5.49, target value: 0\n",
      "prediction: 0.28, target value: 1\n",
      "prediction: -5.18, target value: 0\n",
      "prediction: 2.37, target value: 1\n",
      "prediction: -3.68, target value: 0\n",
      "prediction: -4.04, target value: 0\n",
      "prediction: -4.56, target value: 0\n",
      "prediction: 3.37, target value: 1\n",
      "prediction: -3.18, target value: 0\n",
      "prediction: -7.76, target value: 0\n",
      "prediction: 1.84, target value: 1\n",
      "prediction: 1.83, target value: 1\n",
      "prediction: -3.60, target value: 0\n",
      "prediction: 2.51, target value: 1\n",
      "prediction: 1.21, target value: 1\n",
      "prediction: 5.58, target value: 1\n",
      "prediction: 2.52, target value: 1\n",
      "prediction: -1.79, target value: 0\n",
      "prediction: 2.96, target value: 1\n",
      "prediction: 11.49, target value: 1\n",
      "prediction: 6.17, target value: 1\n",
      "prediction: -1.42, target value: 0\n",
      "prediction: 0.01, target value: 1\n",
      "prediction: -4.90, target value: 0\n",
      "prediction: 1.70, target value: 1\n",
      "prediction: -0.37, target value: 0\n",
      "prediction: -2.23, target value: 0\n",
      "prediction: 6.77, target value: 1\n",
      "prediction: -3.89, target value: 0\n",
      "prediction: 17.05, target value: 1\n",
      "prediction: 0.76, target value: 1\n",
      "prediction: 2.74, target value: 1\n",
      "prediction: 0.44, target value: 1\n",
      "prediction: -2.15, target value: 0\n",
      "prediction: -5.19, target value: 0\n",
      "prediction: 7.43, target value: 1\n",
      "prediction: 8.82, target value: 1\n",
      "prediction: -3.51, target value: 0\n",
      "prediction: -2.09, target value: 0\n",
      "prediction: -4.73, target value: 0\n",
      "prediction: 2.89, target value: 1\n",
      "prediction: -2.76, target value: 0\n",
      "prediction: -1.02, target value: 0\n",
      "prediction: -5.47, target value: 0\n",
      "prediction: -1.19, target value: 0\n",
      "prediction: -1.62, target value: 0\n",
      "prediction: 2.12, target value: 1\n",
      "prediction: 4.53, target value: 1\n",
      "prediction: -4.25, target value: 0\n",
      "prediction: -2.99, target value: 0\n",
      "prediction: 6.44, target value: 1\n",
      "prediction: -5.85, target value: 0\n",
      "prediction: -2.25, target value: 0\n",
      "prediction: 13.01, target value: 1\n",
      "prediction: 4.56, target value: 1\n",
      "prediction: -0.35, target value: 0\n",
      "prediction: 6.60, target value: 1\n",
      "prediction: -2.79, target value: 0\n",
      "prediction: -5.30, target value: 0\n",
      "prediction: -1.68, target value: 0\n",
      "prediction: -2.28, target value: 0\n",
      "prediction: 5.30, target value: 1\n",
      "prediction: -3.41, target value: 0\n",
      "prediction: -3.82, target value: 0\n",
      "prediction: -1.58, target value: 0\n",
      "prediction: -2.59, target value: 0\n",
      "prediction: -3.72, target value: 0\n",
      "prediction: 9.14, target value: 1\n",
      "prediction: -3.82, target value: 0\n",
      "prediction: 8.16, target value: 1\n",
      "prediction: 2.59, target value: 1\n",
      "prediction: 6.29, target value: 1\n",
      "prediction: 0.11, target value: 1\n",
      "prediction: 8.84, target value: 1\n",
      "prediction: 4.14, target value: 1\n",
      "prediction: 8.56, target value: 1\n",
      "prediction: 6.28, target value: 1\n",
      "prediction: 7.09, target value: 1\n",
      "prediction: 0.89, target value: 1\n",
      "prediction: 3.55, target value: 1\n",
      "prediction: -0.82, target value: 1\n",
      "prediction: 3.98, target value: 1\n",
      "prediction: 12.62, target value: 1\n",
      "prediction: -3.48, target value: 0\n",
      "prediction: -2.54, target value: 0\n",
      "prediction: -3.05, target value: 0\n",
      "prediction: -3.69, target value: 0\n",
      "prediction: -4.88, target value: 0\n",
      "prediction: -4.79, target value: 0\n",
      "prediction: 10.23, target value: 1\n",
      "prediction: -5.41, target value: 0\n",
      "prediction: 2.43, target value: 1\n",
      "prediction: -2.48, target value: 0\n",
      "prediction: -5.63, target value: 0\n",
      "prediction: 1.46, target value: 1\n",
      "prediction: -3.43, target value: 0\n",
      "prediction: -2.36, target value: 0\n",
      "prediction: 7.90, target value: 1\n",
      "prediction: -3.94, target value: 0\n",
      "prediction: 6.03, target value: 1\n",
      "prediction: 2.53, target value: 1\n",
      "prediction: -3.63, target value: 0\n",
      "prediction: -4.96, target value: 0\n",
      "prediction: -2.93, target value: 0\n",
      "prediction: -5.69, target value: 0\n",
      "prediction: -3.35, target value: 0\n",
      "prediction: -4.11, target value: 0\n",
      "prediction: -2.04, target value: 0\n",
      "prediction: -0.22, target value: 0\n",
      "prediction: -2.72, target value: 0\n",
      "prediction: -3.36, target value: 0\n",
      "prediction: -4.51, target value: 0\n",
      "prediction: -4.18, target value: 0\n",
      "prediction: -7.29, target value: 0\n",
      "prediction: -3.30, target value: 1\n",
      "prediction: -2.77, target value: 0\n",
      "prediction: -5.08, target value: 0\n",
      "prediction: 8.58, target value: 1\n",
      "prediction: -3.28, target value: 0\n",
      "prediction: 8.32, target value: 1\n",
      "prediction: -5.11, target value: 0\n",
      "prediction: -4.67, target value: 0\n",
      "prediction: -3.73, target value: 0\n",
      "prediction: -4.60, target value: 0\n",
      "prediction: -7.65, target value: 0\n",
      "prediction: -5.44, target value: 0\n",
      "prediction: -4.79, target value: 0\n",
      "prediction: -3.99, target value: 0\n",
      "prediction: -3.15, target value: 0\n",
      "prediction: -3.93, target value: 0\n",
      "prediction: -5.89, target value: 0\n",
      "prediction: -6.80, target value: 0\n",
      "prediction: -5.64, target value: 0\n",
      "prediction: -6.06, target value: 0\n",
      "prediction: 3.56, target value: 1\n",
      "prediction: -3.12, target value: 0\n",
      "prediction: -5.59, target value: 0\n",
      "prediction: -4.45, target value: 0\n",
      "prediction: 3.95, target value: 1\n",
      "prediction: -2.90, target value: 0\n",
      "prediction: 10.35, target value: 1\n",
      "prediction: -4.03, target value: 0\n",
      "prediction: -3.59, target value: 0\n",
      "prediction: -3.83, target value: 0\n",
      "prediction: -5.54, target value: 0\n",
      "prediction: 3.39, target value: 1\n",
      "prediction: 1.48, target value: 1\n",
      "prediction: 1.90, target value: 1\n",
      "prediction: -1.83, target value: 0\n",
      "prediction: -4.12, target value: 0\n",
      "prediction: -5.48, target value: 0\n",
      "prediction: -4.33, target value: 0\n",
      "prediction: 5.04, target value: 1\n",
      "prediction: -4.83, target value: 0\n",
      "prediction: 6.67, target value: 1\n",
      "prediction: -4.35, target value: 0\n",
      "prediction: 12.11, target value: 1\n",
      "prediction: -0.42, target value: 0\n",
      "prediction: -4.46, target value: 0\n",
      "prediction: -3.82, target value: 0\n",
      "prediction: 7.09, target value: 1\n",
      "prediction: -3.52, target value: 0\n",
      "prediction: -5.87, target value: 0\n",
      "prediction: -3.89, target value: 0\n",
      "prediction: -1.52, target value: 0\n",
      "prediction: -4.40, target value: 0\n",
      "prediction: -3.85, target value: 0\n",
      "prediction: -5.06, target value: 0\n",
      "prediction: 4.31, target value: 1\n",
      "prediction: 15.27, target value: 1\n",
      "prediction: 2.92, target value: 1\n",
      "prediction: -5.88, target value: 0\n",
      "prediction: -3.12, target value: 0\n",
      "prediction: -1.37, target value: 0\n",
      "prediction: -3.46, target value: 0\n",
      "prediction: -6.00, target value: 0\n",
      "prediction: -4.53, target value: 0\n",
      "prediction: -5.05, target value: 0\n",
      "prediction: -2.67, target value: 0\n",
      "prediction: -3.06, target value: 0\n",
      "prediction: -0.20, target value: 0\n",
      "prediction: -3.60, target value: 0\n",
      "prediction: 5.23, target value: 1\n",
      "prediction: 8.20, target value: 1\n",
      "prediction: -2.58, target value: 0\n",
      "prediction: 9.84, target value: 1\n",
      "prediction: 10.43, target value: 1\n",
      "prediction: 5.14, target value: 1\n",
      "prediction: -3.18, target value: 0\n",
      "prediction: 4.64, target value: 1\n",
      "prediction: 6.27, target value: 1\n",
      "prediction: -3.20, target value: 0\n",
      "prediction: -0.76, target value: 0\n",
      "prediction: -3.26, target value: 0\n",
      "prediction: -2.28, target value: 0\n",
      "prediction: -2.78, target value: 0\n",
      "prediction: 2.89, target value: 1\n",
      "prediction: -2.41, target value: 0\n",
      "prediction: -4.82, target value: 0\n",
      "prediction: -3.91, target value: 0\n",
      "prediction: -2.30, target value: 0\n",
      "prediction: -3.41, target value: 0\n",
      "prediction: 0.04, target value: 1\n",
      "prediction: -4.11, target value: 0\n",
      "prediction: -4.17, target value: 0\n",
      "prediction: -5.01, target value: 0\n",
      "prediction: 5.07, target value: 1\n",
      "prediction: -5.61, target value: 0\n",
      "prediction: -5.95, target value: 0\n",
      "prediction: 5.07, target value: 1\n",
      "prediction: 10.29, target value: 1\n",
      "prediction: -2.62, target value: 0\n",
      "prediction: -3.26, target value: 0\n",
      "prediction: -0.78, target value: 0\n",
      "prediction: -3.66, target value: 0\n",
      "prediction: -5.34, target value: 0\n",
      "prediction: -3.63, target value: 0\n",
      "prediction: 7.13, target value: 1\n",
      "prediction: -4.30, target value: 0\n",
      "prediction: -3.39, target value: 0\n",
      "prediction: -3.25, target value: 0\n",
      "prediction: -4.95, target value: 0\n",
      "prediction: -3.61, target value: 0\n",
      "prediction: -1.05, target value: 0\n",
      "prediction: -3.31, target value: 0\n",
      "prediction: 4.04, target value: 1\n",
      "prediction: -2.37, target value: 0\n",
      "prediction: -2.75, target value: 0\n",
      "prediction: -3.76, target value: 0\n",
      "prediction: -6.17, target value: 0\n",
      "prediction: 0.22, target value: 0\n",
      "prediction: 0.56, target value: 1\n",
      "prediction: -2.71, target value: 0\n",
      "prediction: -3.96, target value: 0\n",
      "prediction: 7.23, target value: 1\n",
      "prediction: -4.39, target value: 0\n",
      "prediction: -3.90, target value: 0\n",
      "prediction: -3.18, target value: 0\n",
      "prediction: -0.17, target value: 0\n",
      "prediction: -3.03, target value: 0\n",
      "prediction: -1.18, target value: 0\n",
      "prediction: -3.58, target value: 0\n",
      "prediction: -5.70, target value: 0\n",
      "prediction: -3.80, target value: 0\n",
      "prediction: -2.91, target value: 0\n",
      "prediction: -6.19, target value: 0\n",
      "prediction: -4.59, target value: 0\n",
      "prediction: 3.91, target value: 1\n",
      "prediction: -3.17, target value: 0\n",
      "prediction: 6.00, target value: 1\n",
      "prediction: 5.77, target value: 1\n",
      "prediction: -2.46, target value: 0\n",
      "prediction: 1.28, target value: 1\n",
      "prediction: -2.66, target value: 0\n",
      "prediction: -2.60, target value: 0\n",
      "prediction: -2.56, target value: 0\n",
      "prediction: -3.87, target value: 0\n",
      "prediction: -2.32, target value: 0\n",
      "prediction: 3.87, target value: 1\n",
      "prediction: -4.35, target value: 0\n",
      "prediction: -5.85, target value: 0\n",
      "prediction: 1.88, target value: 1\n",
      "prediction: -2.09, target value: 0\n",
      "prediction: 5.81, target value: 1\n",
      "prediction: -1.55, target value: 0\n",
      "prediction: -1.25, target value: 0\n",
      "prediction: 7.46, target value: 1\n",
      "prediction: -3.98, target value: 0\n",
      "prediction: 4.71, target value: 1\n",
      "prediction: -2.53, target value: 0\n",
      "prediction: -1.96, target value: 0\n",
      "prediction: -3.15, target value: 0\n",
      "prediction: -0.89, target value: 0\n",
      "prediction: -1.27, target value: 0\n",
      "prediction: -2.20, target value: 0\n",
      "prediction: -2.64, target value: 0\n",
      "prediction: -4.46, target value: 0\n",
      "prediction: 5.84, target value: 1\n",
      "prediction: 23.27, target value: 1\n",
      "prediction: -2.02, target value: 0\n",
      "prediction: -3.77, target value: 0\n",
      "prediction: -2.93, target value: 0\n",
      "prediction: -0.63, target value: 0\n",
      "prediction: -1.07, target value: 0\n",
      "prediction: -5.18, target value: 0\n",
      "prediction: 5.18, target value: 1\n",
      "prediction: -1.02, target value: 0\n",
      "prediction: -4.32, target value: 0\n",
      "prediction: -2.07, target value: 0\n",
      "prediction: -1.77, target value: 0\n",
      "prediction: -3.30, target value: 0\n",
      "prediction: -4.25, target value: 0\n",
      "prediction: -2.91, target value: 0\n",
      "prediction: -0.79, target value: 0\n",
      "prediction: -3.65, target value: 0\n",
      "prediction: -3.97, target value: 0\n",
      "prediction: 2.56, target value: 1\n",
      "prediction: -3.69, target value: 0\n",
      "prediction: -2.31, target value: 0\n",
      "prediction: -2.19, target value: 0\n",
      "prediction: -2.55, target value: 0\n",
      "prediction: -0.74, target value: 0\n",
      "prediction: -1.56, target value: 0\n",
      "prediction: -2.05, target value: 0\n",
      "prediction: 6.93, target value: 1\n",
      "prediction: -2.80, target value: 0\n",
      "prediction: 0.56, target value: 1\n",
      "prediction: -2.72, target value: 0\n",
      "prediction: -1.02, target value: 0\n",
      "prediction: 4.16, target value: 1\n",
      "prediction: -6.10, target value: 0\n",
      "prediction: -3.18, target value: 0\n",
      "prediction: -1.28, target value: 0\n",
      "prediction: -1.14, target value: 0\n",
      "prediction: -2.94, target value: 0\n",
      "prediction: 4.40, target value: 1\n",
      "prediction: 7.33, target value: 1\n",
      "prediction: -1.35, target value: 0\n",
      "prediction: 2.42, target value: 1\n",
      "prediction: -2.57, target value: 0\n",
      "prediction: 11.00, target value: 1\n",
      "prediction: -3.30, target value: 0\n",
      "prediction: -3.56, target value: 0\n",
      "prediction: -2.68, target value: 0\n",
      "prediction: -3.93, target value: 0\n",
      "prediction: -1.30, target value: 0\n",
      "prediction: 3.98, target value: 1\n",
      "prediction: -4.84, target value: 0\n",
      "prediction: -3.27, target value: 0\n",
      "prediction: 2.28, target value: 1\n",
      "prediction: -1.62, target value: 0\n",
      "prediction: -0.25, target value: 1\n",
      "prediction: -3.26, target value: 0\n",
      "prediction: 4.51, target value: 1\n",
      "prediction: 5.18, target value: 1\n",
      "prediction: -1.17, target value: 0\n",
      "prediction: -2.14, target value: 0\n",
      "prediction: -4.05, target value: 0\n",
      "prediction: 12.13, target value: 1\n",
      "prediction: -5.36, target value: 0\n",
      "prediction: -1.32, target value: 0\n",
      "prediction: -5.08, target value: 0\n",
      "prediction: -5.75, target value: 0\n",
      "prediction: -0.62, target value: 0\n",
      "prediction: -3.84, target value: 0\n",
      "prediction: -1.85, target value: 0\n",
      "prediction: -3.85, target value: 0\n",
      "prediction: -2.34, target value: 0\n",
      "prediction: -2.17, target value: 0\n",
      "prediction: -2.92, target value: 0\n",
      "prediction: 5.93, target value: 1\n",
      "prediction: -3.96, target value: 0\n",
      "prediction: 7.30, target value: 1\n",
      "prediction: 0.63, target value: 1\n",
      "prediction: -0.82, target value: 0\n",
      "prediction: -6.00, target value: 0\n",
      "prediction: -4.71, target value: 0\n",
      "prediction: -4.57, target value: 0\n",
      "prediction: 0.60, target value: 0\n",
      "prediction: -0.68, target value: 0\n",
      "prediction: -1.76, target value: 0\n",
      "prediction: -2.55, target value: 0\n",
      "prediction: -1.94, target value: 0\n",
      "prediction: -5.69, target value: 0\n",
      "prediction: -5.09, target value: 0\n",
      "prediction: -5.48, target value: 0\n",
      "prediction: -3.07, target value: 0\n",
      "prediction: -5.79, target value: 0\n",
      "prediction: -3.68, target value: 0\n",
      "prediction: -2.30, target value: 0\n",
      "prediction: -5.99, target value: 0\n",
      "prediction: -1.98, target value: 0\n",
      "prediction: -3.27, target value: 0\n",
      "prediction: -5.69, target value: 0\n",
      "prediction: -4.68, target value: 0\n",
      "prediction: -1.33, target value: 0\n",
      "prediction: -2.15, target value: 0\n",
      "prediction: -0.69, target value: 0\n",
      "prediction: -4.73, target value: 0\n",
      "prediction: 6.54, target value: 1\n",
      "prediction: 10.51, target value: 1\n",
      "prediction: 9.27, target value: 1\n",
      "prediction: 6.77, target value: 1\n",
      "prediction: 2.18, target value: 1\n",
      "prediction: 12.83, target value: 1\n",
      "prediction: -6.51, target value: 0\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros((X_norm.shape[1]))\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 10000\n",
    "alpha = 1.0e-3\n",
    "lambda_ = 5\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist, W_hist = gradient_descent(X_norm, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations, lambda_)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_norm[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Here we measure both the accuracy of our model and the cost over the gradient descent iterations, so we can see how much it learned per iteration, as well as how accurate it is in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cost versus iteration  \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\n",
    "ax1.plot(J_hist)\n",
    "ax2.plot(100 + np.arange(len(J_hist[100:])), J_hist[100:])\n",
    "ax1.set_title(\"Cost vs. iteration\");  ax2.set_title(\"Cost vs. iteration (tail)\")\n",
    "ax1.set_ylabel('Cost')             ;  ax2.set_ylabel('Cost') \n",
    "ax1.set_xlabel('iteration step')   ;  ax2.set_xlabel('iteration step') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b): \n",
    "    \"\"\"\n",
    "    Predict whether the label is 0 or 1 using learned logistic\n",
    "    regression parameters w\n",
    "    \n",
    "    Args:\n",
    "    X : (ndarray Shape (m, n))\n",
    "    w : (array_like Shape (n,))      Parameters of the model\n",
    "    b : (scalar, float)              Parameter of the model\n",
    "\n",
    "    Returns:\n",
    "    p: (ndarray (m,1))\n",
    "        The predictions for X using a threshold at 0.5\n",
    "    \"\"\"\n",
    "    # number of training examples\n",
    "    m, n = X.shape   \n",
    "    p = np.zeros(m)\n",
    "   \n",
    "    p = np.asarray([1 if sigmoid(np.dot(X[i], w)+b) >= 0.5 else 0 for i in range(m)])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98.066784\n"
     ]
    }
   ],
   "source": [
    "p = predict(X_norm, w_final,b_final)\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
